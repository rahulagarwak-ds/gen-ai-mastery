# Evaluation & Observability

Making AI systems debuggable, measurable, and reliable.

## Topics

| #   | Topic                                                  | Description                              |
| --- | ------------------------------------------------------ | ---------------------------------------- |
| 01  | [Observability](./01-observability/documentation.md)   | Logging, tracing, monitoring LLM calls   |
| 02  | [Evaluation](./02-evaluation/documentation.md)         | Metrics, benchmarks, automated testing   |
| 03  | [Prompt Testing](./03-prompt-testing/documentation.md) | Version control, A/B testing, regression |

## Capstone

**Eval Framework**: Build automated evaluation pipeline for your RAG system.

## Time Estimate

~30-40 hours for complete coverage
