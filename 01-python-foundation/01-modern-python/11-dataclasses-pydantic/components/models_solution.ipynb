{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Pydantic Models for Gen AI\n",
    "\n",
    "Base models and patterns for LLM applications, APIs, and data validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Base Response Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Standard API response models.\"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Any, Generic, Literal, TypeVar\n",
    "from datetime import datetime\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "class APIResponse(BaseModel, Generic[T]):\n",
    "    \"\"\"Generic API response wrapper.\"\"\"\n",
    "    success: bool\n",
    "    data: T | None = None\n",
    "    error: str | None = None\n",
    "    error_code: str | None = None\n",
    "    timestamp: datetime = Field(default_factory=datetime.utcnow)\n",
    "\n",
    "    @classmethod\n",
    "    def ok(cls, data: T) -> \"APIResponse[T]\":\n",
    "        return cls(success=True, data=data)\n",
    "    \n",
    "    @classmethod \n",
    "    def fail(cls, error: str, error_code: str = \"ERROR\") -> \"APIResponse[T]\":\n",
    "        return cls(success=False, error=error, error_code=error_code)\n",
    "\n",
    "\n",
    "class PaginatedResponse(BaseModel, Generic[T]):\n",
    "    \"\"\"Paginated list response.\"\"\"\n",
    "    items: list[T]\n",
    "    total: int\n",
    "    page: int\n",
    "    page_size: int\n",
    "    has_next: bool\n",
    "    has_prev: bool\n",
    "\n",
    "\n",
    "# Test\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "\n",
    "response = APIResponse[User].ok(User(id=1, name=\"Alice\"))\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LLM Message Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Models for LLM chat interactions.\"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class Message(BaseModel):\n",
    "    \"\"\"Single chat message.\"\"\"\n",
    "    role: Literal[\"system\", \"user\", \"assistant\"]\n",
    "    content: str\n",
    "\n",
    "\n",
    "class ChatRequest(BaseModel):\n",
    "    \"\"\"Request to LLM API.\"\"\"\n",
    "    messages: list[Message]\n",
    "    model: str = \"gpt-4\"\n",
    "    temperature: float = Field(default=0.7, ge=0, le=2)\n",
    "    max_tokens: int | None = None\n",
    "    stream: bool = False\n",
    "\n",
    "\n",
    "class Usage(BaseModel):\n",
    "    \"\"\"Token usage stats.\"\"\"\n",
    "    prompt_tokens: int\n",
    "    completion_tokens: int\n",
    "    total_tokens: int\n",
    "\n",
    "\n",
    "class ChatResponse(BaseModel):\n",
    "    \"\"\"Response from LLM API.\"\"\"\n",
    "    content: str\n",
    "    model: str\n",
    "    usage: Usage\n",
    "    finish_reason: Literal[\"stop\", \"length\", \"content_filter\"] | None = None\n",
    "\n",
    "\n",
    "# Test\n",
    "request = ChatRequest(\n",
    "    messages=[\n",
    "        Message(role=\"system\", content=\"You are a helpful assistant.\"),\n",
    "        Message(role=\"user\", content=\"Hello!\"),\n",
    "    ],\n",
    "    temperature=0.5\n",
    ")\n",
    "print(request.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Structured Output Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Models for structured LLM output parsing.\"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class ExtractedEntity(BaseModel):\n",
    "    \"\"\"Entity extracted from text.\"\"\"\n",
    "    name: str\n",
    "    entity_type: str\n",
    "    confidence: float = Field(ge=0, le=1)\n",
    "    start_char: int | None = None\n",
    "    end_char: int | None = None\n",
    "\n",
    "\n",
    "class Sentiment(BaseModel):\n",
    "    \"\"\"Sentiment analysis result.\"\"\"\n",
    "    label: Literal[\"positive\", \"negative\", \"neutral\"]\n",
    "    score: float = Field(ge=0, le=1)\n",
    "    explanation: str | None = None\n",
    "\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    \"\"\"Text classification result.\"\"\"\n",
    "    category: str\n",
    "    confidence: float = Field(ge=0, le=1)\n",
    "    subcategories: list[str] = []\n",
    "\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    \"\"\"Text summarization result.\"\"\"\n",
    "    summary: str\n",
    "    key_points: list[str]\n",
    "    word_count: int\n",
    "\n",
    "\n",
    "class QAResult(BaseModel):\n",
    "    \"\"\"Question answering result.\"\"\"\n",
    "    answer: str\n",
    "    confidence: float = Field(ge=0, le=1)\n",
    "    sources: list[str] = []\n",
    "    is_answerable: bool = True\n",
    "\n",
    "\n",
    "# Test\n",
    "result = Sentiment(label=\"positive\", score=0.92, explanation=\"Enthusiastic tone\")\n",
    "print(result.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. RAG Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Models for RAG (Retrieval Augmented Generation) pipelines.\"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class Document(BaseModel):\n",
    "    \"\"\"Document chunk for RAG.\"\"\"\n",
    "    id: str\n",
    "    content: str\n",
    "    metadata: dict[str, Any] = {}\n",
    "    embedding: list[float] | None = None\n",
    "\n",
    "\n",
    "class SearchResult(BaseModel):\n",
    "    \"\"\"Search result from vector store.\"\"\"\n",
    "    document: Document\n",
    "    score: float\n",
    "    rank: int\n",
    "\n",
    "\n",
    "class RAGQuery(BaseModel):\n",
    "    \"\"\"RAG query request.\"\"\"\n",
    "    query: str\n",
    "    k: int = Field(default=5, ge=1, le=20)\n",
    "    filter: dict[str, Any] | None = None\n",
    "    rerank: bool = False\n",
    "\n",
    "\n",
    "class RAGResponse(BaseModel):\n",
    "    \"\"\"RAG query response.\"\"\"\n",
    "    answer: str\n",
    "    sources: list[SearchResult]\n",
    "    query: str\n",
    "    model: str\n",
    "\n",
    "\n",
    "# Test\n",
    "doc = Document(\n",
    "    id=\"doc_001\",\n",
    "    content=\"Python is a programming language.\",\n",
    "    metadata={\"source\": \"wiki\", \"page\": 1}\n",
    ")\n",
    "print(doc.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configuration Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Application configuration models.\"\"\"\n",
    "\n",
    "from pydantic import BaseModel, Field, SecretStr\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class LLMConfig(BaseModel):\n",
    "    \"\"\"LLM provider configuration.\"\"\"\n",
    "    provider: Literal[\"openai\", \"anthropic\", \"google\"]\n",
    "    model: str\n",
    "    api_key: SecretStr\n",
    "    temperature: float = Field(default=0.7, ge=0, le=2)\n",
    "    max_tokens: int = 4096\n",
    "    timeout: float = 30.0\n",
    "\n",
    "\n",
    "class VectorStoreConfig(BaseModel):\n",
    "    \"\"\"Vector store configuration.\"\"\"\n",
    "    provider: Literal[\"pinecone\", \"weaviate\", \"chroma\", \"qdrant\"]\n",
    "    index_name: str\n",
    "    dimension: int = 1536\n",
    "    metric: Literal[\"cosine\", \"euclidean\", \"dot\"] = \"cosine\"\n",
    "\n",
    "\n",
    "class AppConfig(BaseModel):\n",
    "    \"\"\"Main application configuration.\"\"\"\n",
    "    app_name: str\n",
    "    debug: bool = False\n",
    "    log_level: Literal[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\"] = \"INFO\"\n",
    "    llm: LLMConfig\n",
    "    vector_store: VectorStoreConfig | None = None\n",
    "\n",
    "\n",
    "# Test\n",
    "config = AppConfig(\n",
    "    app_name=\"MyApp\",\n",
    "    llm=LLMConfig(\n",
    "        provider=\"openai\",\n",
    "        model=\"gpt-4\",\n",
    "        api_key=\"sk-secret\"\n",
    "    )\n",
    ")\n",
    "print(config.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-One: models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.py - Copy to create module\n",
    "\"\"\"\n",
    "Pydantic models for Gen AI applications.\n",
    "\n",
    "Usage:\n",
    "    from models import ChatRequest, Message, Document, RAGQuery\n",
    "\"\"\"\n",
    "\n",
    "__all__ = [\n",
    "    # API\n",
    "    \"APIResponse\",\n",
    "    \"PaginatedResponse\",\n",
    "    # LLM\n",
    "    \"Message\",\n",
    "    \"ChatRequest\",\n",
    "    \"ChatResponse\",\n",
    "    \"Usage\",\n",
    "    # Structured Output\n",
    "    \"ExtractedEntity\",\n",
    "    \"Sentiment\",\n",
    "    \"Classification\",\n",
    "    \"Summary\",\n",
    "    \"QAResult\",\n",
    "    # RAG\n",
    "    \"Document\",\n",
    "    \"SearchResult\",\n",
    "    \"RAGQuery\",\n",
    "    \"RAGResponse\",\n",
    "    # Config\n",
    "    \"LLMConfig\",\n",
    "    \"VectorStoreConfig\",\n",
    "    \"AppConfig\",\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
