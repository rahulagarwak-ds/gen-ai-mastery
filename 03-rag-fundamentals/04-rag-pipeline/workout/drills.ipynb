{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workout: RAG Pipeline\n",
    "\n",
    "## Setup\n",
    "```bash\n",
    "uv add chromadb openai sentence-transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 1: Basic RAG Query ðŸŸ¢\n",
    "**Task:** Implement simple retrieve + generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import chromadb\n",
    "\n",
    "client = OpenAI()\n",
    "chroma = chromadb.Client()\n",
    "collection = chroma.create_collection(\"test\")\n",
    "\n",
    "# Add some documents\n",
    "collection.add(\n",
    "    documents=[\n",
    "        \"Python was created by Guido van Rossum in 1991.\",\n",
    "        \"JavaScript was created by Brendan Eich in 1995.\",\n",
    "        \"Rust was created by Graydon Hoare in 2010.\"\n",
    "    ],\n",
    "    ids=[\"python\", \"js\", \"rust\"]\n",
    ")\n",
    "\n",
    "def rag_query(question: str) -> str:\n",
    "    # 1. Retrieve relevant docs\n",
    "    # 2. Build context\n",
    "    # 3. Generate answer with OpenAI\n",
    "    pass\n",
    "\n",
    "# answer = rag_query(\"Who created Python?\")\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 2: Query Expansion ðŸŸ¡\n",
    "**Task:** Generate multiple search queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def expand_query(query: str, n: int = 3) -> list[str]:\n",
    "    \"\"\"Generate n alternative queries.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Test\n",
    "queries = expand_query(\"What are the benefits of exercise?\")\n",
    "print(queries)\n",
    "# Should return original + alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 3: Context Formatting ðŸŸ¢\n",
    "**Task:** Format retrieved documents for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context(documents: list[dict]) -> str:\n",
    "    \"\"\"Format documents for LLM context.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Each document has: content, metadata (source, page)\n",
    "# Format as:\n",
    "# [Source 1: filename, page X]\n",
    "# Content...\n",
    "#\n",
    "# [Source 2: filename, page Y]\n",
    "# Content...\n",
    "\n",
    "docs = [\n",
    "    {\"content\": \"First doc content\", \"metadata\": {\"source\": \"a.pdf\", \"page\": 1}},\n",
    "    {\"content\": \"Second doc content\", \"metadata\": {\"source\": \"b.pdf\", \"page\": 5}},\n",
    "]\n",
    "print(format_context(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 4: Simple Reranker ðŸŸ¡\n",
    "**Task:** Rerank using cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "def rerank(query: str, documents: list[str], top_k: int = 3) -> list[tuple[str, float]]:\n",
    "    \"\"\"Rerank documents and return top-k with scores.\"\"\"\n",
    "    pass\n",
    "\n",
    "docs = [\n",
    "    \"Python is a programming language\",\n",
    "    \"The python snake is found in Asia\",\n",
    "    \"Python was created by Guido van Rossum\",\n",
    "    \"I love cooking\"\n",
    "]\n",
    "\n",
    "results = rerank(\"Who made the Python language?\", docs, top_k=2)\n",
    "for doc, score in results:\n",
    "    print(f\"{score:.3f}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 5: RAG with Sources ðŸŸ¡\n",
    "**Task:** Generate answer with citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_with_citations(question: str, retriever) -> dict:\n",
    "    \"\"\"Return answer with source citations.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Return format:\n",
    "# {\n",
    "#     \"answer\": \"Answer text with [1] citations\",\n",
    "#     \"sources\": [\n",
    "#         {\"id\": 1, \"content\": \"...\", \"source_file\": \"...\"}\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 6: Streaming RAG ðŸŸ¡\n",
    "**Task:** Stream the generated response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "def stream_rag(question: str, context: list[str]):\n",
    "    \"\"\"Stream RAG answer token by token.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Usage\n",
    "# for chunk in stream_rag(\"What is Python?\", [\"Python is...\"]):\n",
    "#     print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 7: Hybrid Search ðŸ”´\n",
    "**Task:** Combine semantic + keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(\n",
    "    query: str,\n",
    "    collection,\n",
    "    embed_fn,\n",
    "    k: int = 5,\n",
    "    alpha: float = 0.5  # semantic weight\n",
    ") -> list[dict]:\n",
    "    \"\"\"Combine semantic and keyword results.\"\"\"\n",
    "    pass\n",
    "\n",
    "# alpha=1.0 â†’ pure semantic\n",
    "# alpha=0.0 â†’ pure keyword\n",
    "# alpha=0.5 â†’ balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 8: RAG Pipeline Class ðŸ”´\n",
    "**Task:** Build complete RAG class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class RAGResult:\n",
    "    answer: str\n",
    "    sources: list[dict]\n",
    "    query: str\n",
    "\n",
    "class RAGPipeline:\n",
    "    def __init__(self, collection_name: str = \"docs\"):\n",
    "        pass\n",
    "\n",
    "    def ingest(self, documents: list[str], ids: list[str]):\n",
    "        \"\"\"Add documents to the store.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def query(\n",
    "        self,\n",
    "        question: str,\n",
    "        k: int = 5,\n",
    "        use_rerank: bool = True\n",
    "    ) -> RAGResult:\n",
    "        \"\"\"End-to-end RAG query.\"\"\"\n",
    "        pass\n",
    "\n",
    "# Test\n",
    "# rag = RAGPipeline()\n",
    "# rag.ingest([\"Doc 1 content\", \"Doc 2 content\"], [\"d1\", \"d2\"])\n",
    "# result = rag.query(\"Find information about...\")\n",
    "# print(result.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 9: Retrieval Evaluation ðŸ”´\n",
    "**Task:** Compute retrieval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieval(\n",
    "    test_cases: list[tuple[str, list[str]]],  # (query, expected_docs)\n",
    "    retriever,\n",
    "    k: int = 5\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Compute:\n",
    "    - Hit Rate @ K\n",
    "    - MRR (Mean Reciprocal Rank)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Test cases: [(query, [expected doc ids]), ...]\n",
    "test_cases = [\n",
    "    (\"Who created Python?\", [\"python_history\"]),\n",
    "    (\"JavaScript runtime\", [\"nodejs\", \"browser_js\"]),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 10: Conversational RAG ðŸ”´\n",
    "**Task:** RAG with conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationalRAG:\n",
    "    def __init__(self, collection):\n",
    "        self.collection = collection\n",
    "        self.history = []\n",
    "\n",
    "    def query(self, question: str) -> str:\n",
    "        # 1. Consider history for context\n",
    "        # 2. Retrieve relevant docs\n",
    "        # 3. Generate answer with full history\n",
    "        # 4. Update history\n",
    "        pass\n",
    "\n",
    "    def clear_history(self):\n",
    "        self.history = []\n",
    "\n",
    "# Usage\n",
    "# rag = ConversationalRAG(collection)\n",
    "# print(rag.query(\"What is Python?\"))\n",
    "# print(rag.query(\"Who created it?\"))  # Should understand \"it\" = Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Self-Check\n",
    "\n",
    "- [ ] Can implement basic RAG (retrieve + generate)\n",
    "- [ ] Can format context for LLM\n",
    "- [ ] Can use rerankers to improve retrieval\n",
    "- [ ] Can generate answers with citations\n",
    "- [ ] Can build complete RAG pipelines\n",
    "- [ ] Understand evaluation metrics (hit rate, MRR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
