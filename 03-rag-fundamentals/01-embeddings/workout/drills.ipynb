{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workout: Embeddings\n",
    "\n",
    "## Setup\n",
    "```bash\n",
    "uv add openai sentence-transformers numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 1: OpenAI Embedding 游릭\n",
    "**Task:** Create an embedding using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "text = \"Python is a great programming language\"\n",
    "\n",
    "# Create embedding using text-embedding-3-small\n",
    "# Print the dimension and first 5 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 2: Batch Embeddings 游릭\n",
    "**Task:** Embed multiple texts in a single API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "texts = [\n",
    "    \"Machine learning is fascinating\",\n",
    "    \"Deep learning uses neural networks\",\n",
    "    \"Natural language processing handles text\"\n",
    "]\n",
    "\n",
    "# Embed all texts in one API call\n",
    "# Print the shape of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 3: Sentence Transformers 游릭\n",
    "**Task:** Use a local embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load all-MiniLM-L6-v2 model\n",
    "# Embed \"Hello, world!\"\n",
    "# Print dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 4: Cosine Similarity 游리\n",
    "**Task:** Implement cosine similarity from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Test with these vectors\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([1, 2, 3])  # Same -> should be 1.0\n",
    "c = np.array([-1, -2, -3])  # Opposite -> should be -1.0\n",
    "d = np.array([3, 2, 1])  # Similar -> should be ~0.86\n",
    "\n",
    "print(cosine_similarity(a, b))\n",
    "print(cosine_similarity(a, c))\n",
    "print(cosine_similarity(a, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 5: Semantic Similarity 游리\n",
    "**Task:** Compare text similarity using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_embedding(text: str) -> list[float]:\n",
    "    response = client.embeddings.create(\n",
    "        model=\"text-embedding-3-small\",\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Compare these pairs and print similarity scores:\n",
    "pairs = [\n",
    "    (\"I love Python\", \"Python is my favorite\"),  # Very similar\n",
    "    (\"I love Python\", \"I hate Python\"),  # Opposite sentiment\n",
    "    (\"I love Python\", \"The weather is nice\"),  # Unrelated\n",
    "]\n",
    "\n",
    "# What do you notice about the scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 6: Find Most Similar 游리\n",
    "**Task:** Find the most similar document to a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "documents = [\n",
    "    \"Python is a programming language\",\n",
    "    \"Machine learning uses algorithms\",\n",
    "    \"Cats are popular pets\",\n",
    "    \"Neural networks are inspired by brains\",\n",
    "    \"Dogs are loyal companions\"\n",
    "]\n",
    "\n",
    "query = \"artificial intelligence\"\n",
    "\n",
    "# Embed all documents and query\n",
    "# Find the most similar document\n",
    "# Print the result with similarity score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 7: Embedding Cache 游리\n",
    "**Task:** Implement a simple embedding cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "class SimpleCache:\n",
    "    def __init__(self, cache_file: str = \"embeddings.json\"):\n",
    "        self.cache_file = Path(cache_file)\n",
    "        self._cache = self._load()\n",
    "\n",
    "    def _load(self) -> dict:\n",
    "        pass\n",
    "\n",
    "    def _save(self):\n",
    "        pass\n",
    "\n",
    "    def get(self, text: str) -> list[float] | None:\n",
    "        pass\n",
    "\n",
    "    def set(self, text: str, embedding: list[float]):\n",
    "        pass\n",
    "\n",
    "# Test the cache\n",
    "# cache = SimpleCache()\n",
    "# cache.set(\"hello\", [0.1, 0.2, 0.3])\n",
    "# result = cache.get(\"hello\")\n",
    "# assert result == [0.1, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 8: Dimension Reduction 游리\n",
    "**Task:** Use OpenAI's dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "text = \"Dimension reduction can save storage space\"\n",
    "\n",
    "# Create embeddings at different dimensions\n",
    "# Compare: 1536 (default), 512, 256\n",
    "\n",
    "dims = [1536, 512, 256]\n",
    "for dim in dims:\n",
    "    # Get embedding with that dimension\n",
    "    # Print dimension and first 3 values\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 9: Model Comparison 游댮\n",
    "**Task:** Compare OpenAI and Sentence Transformers quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "test_pairs = [\n",
    "    (\"A dog is running\", \"A canine is jogging\"),\n",
    "    (\"The cat sleeps\", \"Python programming\"),\n",
    "    (\"I love coffee\", \"Coffee is my favorite drink\"),\n",
    "]\n",
    "\n",
    "# Get similarities using both:\n",
    "# 1. OpenAI text-embedding-3-small\n",
    "# 2. Sentence Transformers all-MiniLM-L6-v2\n",
    "\n",
    "# Compare the rankings - are they consistent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 10: Semantic Search Function 游댮\n",
    "**Task:** Build a complete semantic search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    text: str\n",
    "    score: float\n",
    "    index: int\n",
    "\n",
    "def semantic_search(\n",
    "    query: str,\n",
    "    documents: list[str],\n",
    "    embed_fn: Callable[[str], list[float]],\n",
    "    top_k: int = 3\n",
    ") -> list[SearchResult]:\n",
    "    \"\"\"\n",
    "    Perform semantic search.\n",
    "\n",
    "    Args:\n",
    "        query: Search query\n",
    "        documents: List of documents to search\n",
    "        embed_fn: Function to create embeddings\n",
    "        top_k: Number of results to return\n",
    "\n",
    "    Returns:\n",
    "        List of SearchResult sorted by score (highest first)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# Test with this data\n",
    "docs = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"Python is a popular programming language\",\n",
    "    \"Machine learning models learn from data\",\n",
    "    \"The lazy dog sleeps all day\",\n",
    "    \"Deep learning is a subset of machine learning\",\n",
    "]\n",
    "\n",
    "# results = semantic_search(\n",
    "#     query=\"AI and neural networks\",\n",
    "#     documents=docs,\n",
    "#     embed_fn=get_embedding,\n",
    "#     top_k=2\n",
    "# )\n",
    "\n",
    "# for r in results:\n",
    "#     print(f\"{r.score:.3f}: {r.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Self-Check\n",
    "\n",
    "- [ ] Can create embeddings with OpenAI and Sentence Transformers\n",
    "- [ ] Understand cosine similarity and when to use it\n",
    "- [ ] Can implement semantic search\n",
    "- [ ] Know how to cache embeddings for efficiency\n",
    "- [ ] Understand trade-offs between different models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
