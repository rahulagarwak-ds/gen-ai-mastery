{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workout: Tool Use\n",
    "\n",
    "## Setup\n",
    "```bash\n",
    "uv add openai anthropic\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 1: Define Tool Schema 游릭\n",
    "**Task:** Create OpenAI-compatible tool schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for a calculator tool that:\n",
    "# - Takes \"expression\" (required string)\n",
    "# - Returns the result\n",
    "\n",
    "calculator_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        # Complete the schema\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 2: Basic Tool Call 游릭\n",
    "**Task:** Make LLM request tool use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "tools = [calculator_tool]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is 15 * 23?\"}],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# Print the tool call details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 3: Execute Tool 游리\n",
    "**Task:** Execute tool and continue conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(expression: str) -> float:\n",
    "    return eval(expression)\n",
    "\n",
    "# 1. Get tool call from response\n",
    "# 2. Execute the tool\n",
    "# 3. Send results back to LLM\n",
    "# 4. Get final response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 4: Multiple Tools 游리\n",
    "**Task:** Provide multiple tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schemas for:\n",
    "# - get_weather(location: str) -> dict\n",
    "# - search_web(query: str) -> list\n",
    "# - calculate(expression: str) -> float\n",
    "\n",
    "tools = [\n",
    "    # Your schemas here\n",
    "]\n",
    "\n",
    "# Test with: \"What's 100/5 and what's the weather in Paris?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 5: Tool Decorator 游리\n",
    "**Task:** Create decorator to generate schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool(description: str):\n",
    "    def decorator(func):\n",
    "        # Generate schema from function signature\n",
    "        # Store as func._schema\n",
    "        pass\n",
    "    return decorator\n",
    "\n",
    "@tool(\"Add two numbers\")\n",
    "def add(a: int, b: int) -> int:\n",
    "    return a + b\n",
    "\n",
    "# print(add._schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 6: Tool Registry 游리\n",
    "**Task:** Build a tool registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolRegistry:\n",
    "    def __init__(self):\n",
    "        self._tools = {}\n",
    "\n",
    "    def register(self, func):\n",
    "        pass\n",
    "\n",
    "    def get_schemas(self) -> list:\n",
    "        pass\n",
    "\n",
    "    def execute(self, name: str, args: dict):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 7: Error Handling 游리\n",
    "**Task:** Handle tool execution errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_execute(registry, call):\n",
    "    \"\"\"Execute tool with error handling.\"\"\"\n",
    "    try:\n",
    "        # Execute tool\n",
    "        # Return result\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        # Return error message\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Drill 8: Parallel Execution 游댮\n",
    "**Task:** Execute multiple tools in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def execute_parallel(calls: list, registry):\n",
    "    \"\"\"Execute all tool calls concurrently.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Test with 3 tool calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Self-Check\n",
    "\n",
    "- [ ] Can define OpenAI/Anthropic tool schemas\n",
    "- [ ] Can detect when LLM requests tool use\n",
    "- [ ] Can execute tools and return results\n",
    "- [ ] Can handle errors gracefully\n",
    "- [ ] Can build reusable tool registries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
